{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "26th Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12i9GLwwU_kV2dW2lxTo1gNyJnR8C-gUr",
      "authorship_tag": "ABX9TyPzcoKw35Czxo8XMFLwfA8H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pafernannapi18/GithubIntro/blob/main/26th_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 1] Creating a code to determine the initial weight value.\n",
        "\n",
        "[Problem 2] Implementation of forward propagation\n",
        "\n",
        "[Problem 3] Implementation of cross entropy error\n",
        "\n",
        "[Problem 4] Implementation of backpropagation\n",
        "\n",
        "[Problem 5] Estimation"
      ],
      "metadata": {
        "id": "8R3QI7s3kors"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "4Ai_hdl6jRUA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train[0].dtype)\n",
        "print(X_train[0].shape)\n",
        "print(type(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYqMTpQflWhE",
        "outputId": "44c30cc3-d13b-4d69-c7a1-5cf407109094"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n",
            "(28, 28)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "metadata": {
        "id": "MP1tWKD2ld_H"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28, 28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('Label :{}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "mt26vJSclhE2",
        "outputId": "c641ab0f-84ef-43eb-b7d0-41356b372618"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "image = image.astype(np.float) # Convert to float type\n",
        "image -= 105.35 # Intentionally try to create a negative decimal value\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()\n",
        "print(image) # Check the value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_WL4lcXlkYn",
        "outputId": "66b729a1-9011-4e90-df3f-fd3fc2e6273d"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
            "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
            "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
            "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
            "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
            "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
            "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
            "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
            "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
            "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
            "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
            "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
            "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
            "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
            "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
            "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
            "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
            "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
            "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fN801h-Ywig2",
        "outputId": "b52a7797-01d7-45c2-aa81-74cf02d2644a"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f776ae91b90>"
            ]
          },
          "metadata": {},
          "execution_count": 233
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhcDg8WJloSy",
        "outputId": "7d248649-5aa9-4fc7-c2dc-3c3ae3673e81"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psB3vJjplvUM",
        "outputId": "e8d6463d-231c-4459-f721-f87a09f11cff"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-Batch Processing"
      ],
      "metadata": {
        "id": "WYzpHFSnl0wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "metadata": {
        "id": "DMtgSndHlyRA"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 784\n",
        "n_nodes1 = 400\n",
        "n_output = 10\n",
        "sigma = 0.01 # Standard deviation of Gaussian distribution\n",
        "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
        "# W1: (784, 400)\n",
        "n_nodes2 = 200\n",
        "n_nodes3 = 10\n",
        "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "b1 = sigma * np.random.randn(n_nodes1)\n",
        "b2 = sigma * np.random.randn(n_nodes2)\n",
        "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
        "b3 = sigma * np.random.randn(n_nodes3)\n",
        "print(\"W1-->\", W1.shape)\n",
        "print(\"W2-->\", W2.shape)\n",
        "print(\"b1-->\", b1.shape)\n",
        "print(\"b2-->\", b2.shape)\n",
        "print(\"W3-->\", W3.shape)\n",
        "print(\"b3-->\", b3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SEWQUllm3Nz",
        "outputId": "16348c94-0aee-4a34-f288-333943a77a3e"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1--> (784, 400)\n",
            "W2--> (400, 200)\n",
            "b1--> (400,)\n",
            "b2--> (200,)\n",
            "W3--> (200, 10)\n",
            "b3--> (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchSimpleNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose = False):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20\n",
        "        self.n_features = 784\n",
        "        self.n_nodes1 = 400\n",
        "        self.n_nodes2 = 200\n",
        "        self.n_output = 10\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.01\n",
        "        self.epoch = 10\n",
        "\n",
        "        \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "      self.loss_train = []\n",
        "      self.loss_test = []\n",
        "      self.W1 = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
        "      self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
        "      self.W3 = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
        "      self.B1 = self.sigma * np.random.randn(1, self.n_nodes1)\n",
        "      self.B2 = self.sigma * np.random.randn(1, self.n_nodes2)\n",
        "      self.B3 = self.sigma * np.random.randn(1, self.n_output)\n",
        "\n",
        "      for _ in range(self.epoch):\n",
        "        get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "        for mini_X_train, mini_y_train in get_mini_batch:\n",
        "          self.forward(mini_X_train)\n",
        "          self.backward(mini_X_train, mini_y_train)\n",
        "        self.forward(X)\n",
        "        self.loss_train.append(self.cross_entropy_error(y, self.Z3))\n",
        "        if X_val is not None:\n",
        "          self.forward(X_val)  \n",
        "          self.loss_test.append(self.cross_entropy_error(y_val, self.Z3))\n",
        "\n",
        "      if self.verbose:\n",
        "        print(self.loss_train)    \n",
        "\n",
        "    def forward(self, X):\n",
        "      self.A1 = X @ self.W1 + self.B1\n",
        "      self.Z1 = self.tanh_function(self.A1)    \n",
        "      self.A2 = self.Z1 @ self.W2 + self.B2\n",
        "      self.Z2 = self.tanh_function(self.A2)\n",
        "      self.A3 = self.Z2 @ self.W3 + self.B3\n",
        "      self.Z3 = self.softmax(self.A3)\n",
        "\n",
        "    def backward(self, mini_X, mini_y):\n",
        "      dA3 = self.Z3 - mini_y\n",
        "      dB3 = np.sum(dA3, axis=0)\n",
        "      dW3 = self.Z2.T @ dA3\n",
        "      dZ2 = dA3 @ self.W3.T\n",
        "      dA2 = dZ2 * (1-self.tanh_function(self.A2)**2)\n",
        "      dB2 = np.sum(dA2, axis=0)\n",
        "      dW2 = self.Z1.T @ dA2\n",
        "      dZ1 = dA2 @ self.W2.T\n",
        "      dA1 = dZ1 * (1-self.tanh_function(self.A1)**2)\n",
        "      dB1 = np.sum(dA1, axis=0)\n",
        "      dW1 = mini_X.T @ dA1\n",
        "      self.W3 -= self.lr *dW3\n",
        "      self.B3 -= self.lr *dB3\n",
        "      self.W2 -= self.lr *dW2\n",
        "      self.B2 -= self.lr *dB2\n",
        "      self.W1 -= self.lr *dW1\n",
        "      self.B1 -= self.lr *dB1\n",
        "\n",
        "    def sigmoid_function(self, A):\n",
        "      return 1/(1+np.exp(-A))\n",
        "\n",
        "    def tanh_function(self, A):\n",
        "      return np.tanh(A)\n",
        "\n",
        "    def softmax(self, A):\n",
        "      return np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "\n",
        "    def cross_entropy_error(self, y, Z):\n",
        "      L = -np.sum(y*np.log(Z))/len(y)\n",
        "      return L\n",
        "\n",
        "    def predict(self, X):\n",
        "      self.forward(X)\n",
        "      return np.argmax(self.Z3, axis=1)      "
      ],
      "metadata": {
        "id": "ah6l8_o8m4Mu"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 【Problem 6】Learning and estimation"
      ],
      "metadata": {
        "id": "62vOO1XInIPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
      ],
      "metadata": {
        "id": "Agt2xpbGnJ5n"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN = ScratchSimpleNeuralNetrowkClassifier()\n",
        "NN.fit(X_train, y_test_one_hot, X_val, y_test_one_hot)\n",
        "pred_train = NN.predict(X_train)\n",
        "pred_test = NN.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "BCiZ4IjznhEb",
        "outputId": "3b4aeb4b-bd02-418b-d3c5-5168ad475640"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-241-55c9d7452350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScratchSimpleNeuralNetrowkClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-238-335a1d51c6ad>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mget_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetMiniBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmini_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_y_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_mini_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-236-258abfc90155>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, batch_size, seed)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mshuffle_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 37957 is out of bounds for axis 0 with size 12000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, pred_train)"
      ],
      "metadata": {
        "id": "nr0h3HXSno_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_val, pred_test)"
      ],
      "metadata": {
        "id": "fJqmgpCbnyMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 【Problem 7】Learning curve plot"
      ],
      "metadata": {
        "id": "BRV7ufKGofxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, NN.epoch+1)), NN.loss_train, label='train')\n",
        "plt.plot(list(range(1, NN.epoch+1)), NN.loss_test, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, NN.epoch+1)));"
      ],
      "metadata": {
        "id": "uQUxHUy_oieZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 8 - Confirmation of Misclassification\n",
        "Being able to see what the misclassified images look like"
      ],
      "metadata": {
        "id": "zQkhe-eTo3n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_test\n",
        "num = 64\n",
        "true_false = y_pred==y_val\n",
        "false_list = np.where(true_false==False)[0].astype(np.int)\n",
        "if false_list.shape[0] < num:\n",
        "  num = false_list.shape[0]\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "fig.subplots_adjust(left=0, right=0.8, top=0.8, hspace=1, wspace=0.5)\n",
        "for i in range(num):\n",
        "  ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
        "  ax.set_title(\"{}/{}\".format(y_pred[false_list[i]], y_val[false_list[i]]))\n",
        "  ax.imshow(X_val.reshape(-1, 28, 28)[false_list[i]], cmap='gray')"
      ],
      "metadata": {
        "id": "wa163ID7o8sc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}