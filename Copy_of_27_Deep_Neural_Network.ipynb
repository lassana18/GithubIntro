{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 27_Deep Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pafernannapi18/GithubIntro/blob/main/Copy_of_27_Deep_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 - Fully Connected Layers "
      ],
      "metadata": {
        "id": "eLTL_n7YjQtq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p0kFuQnhgHvg",
        "outputId": "f48e2fce-de46-4e5f-f253-e319bb577825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "  def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "    self.n_nodes1 = n_nodes1\n",
        "    self.n_nodes2 = n_nodes2\n",
        "    self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "    self.B = initializer.B(self.n_nodes2)\n",
        "    self.optimizer = optimizer\n",
        "    self.HW = 0\n",
        "    self.HB = 0\n",
        "\n",
        "  def forward(self, X):\n",
        "      self.Z = X\n",
        "      self.A = X @ self.W + self.B\n",
        "      return self.A \n",
        "\n",
        "  def backward(self, dA):\n",
        "      self.dB = np.sum(dA, axis=0)\n",
        "      self.dW  = self.Z.T @ dA\n",
        "      self.dZ = dA @ self.W.T\n",
        "      self = self.optimizer.update(self)\n",
        "      return self.dZ    "
      ],
      "metadata": {
        "id": "nuCAz5jZm88k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2"
      ],
      "metadata": {
        "id": "o999ymNCq9jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    \"\"\"\n",
        "    Simple initialization with Gaussian distribution\n",
        "    Parameters\n",
        "    ----------\n",
        "    sigma : float\n",
        "      Standard deviation of Gaussian distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          Number of nodes in the previous layer\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        W :\n",
        "        \"\"\"\n",
        "        W = self.sigma* np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          Number of nodes in the later layer\n",
        "        Returns\n",
        "        ----------\n",
        "        B :\n",
        "        \"\"\"\n",
        "        B = self.sigma* np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "91ikcRHivG4f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "problem 3 - Optimization Methods"
      ],
      "metadata": {
        "id": "v8i0FP7TwJU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    Stochastic gradient descent\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : Learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr* layer.dW/len(layer.z)\n",
        "      layer.B -= self.lr* layer.dB/len(layer.z)\n",
        "      return layer\n",
        "    \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "uB_cgLY5wSQz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4 - Activation Functions"
      ],
      "metadata": {
        "id": "kVX7oBd_xl4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "  \n",
        "  def forward(self, A):\n",
        "    self.A = A\n",
        "    Z = 1/(1 + np.exp(-self.A))\n",
        "    return Z\n",
        "  def backward(self, dZ):\n",
        "    dA = dZ*((1/(1 + np.exp(-self.A))) - (1/(1 + np.exp(-self.A)))**2)\n",
        "    return dA"
      ],
      "metadata": {
        "id": "unEk_eg5xtQm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "  \n",
        "  def forward(self, A):\n",
        "    Z = np.tanh(self.A)\n",
        "    return Z\n",
        "  def backward(self, dZ):\n",
        "    dA = dz*(1 - np.tanh(self.A)**2)\n",
        "    return dA"
      ],
      "metadata": {
        "id": "bvuBGI491P_m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax:\n",
        "\n",
        "  def forward(self, A):\n",
        "    Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "    return Z\n",
        "  \n",
        "  def backward(self, Z, y):\n",
        "    dA = Z -y \n",
        "    loss = - np.sum(y*np.log(Z)) / len(y)\n",
        "    return dA, loss\n"
      ],
      "metadata": {
        "id": "8iydHnvO2KgY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5 - Creation of the ReLU Class"
      ],
      "metadata": {
        "id": "bk87kvQc67og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "\n",
        "  def forward(self, A): \n",
        "    self.A = A\n",
        "    Z = np.maximum(0, A)\n",
        "    return Z \n",
        "  \n",
        "  def backward(self, dZ):\n",
        "    dA = dZ * np.where(self.A > 0, 1, 0)\n",
        "    return dA "
      ],
      "metadata": {
        "id": "olezBeBT7KOG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 6 - Initial value of weight"
      ],
      "metadata": {
        "id": "WUfhZjAl9d3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial value of Xavier"
      ],
      "metadata": {
        "id": "LAKEO0XP-vlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "\n",
        "  def __init__(self, sigma):\n",
        "    _ = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    self.sigma = 1 / np.sqt(n_nodes1)\n",
        "    W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
        "    return W \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    B = self.sigma*np.random.randn(1, n_nodes2)\n",
        "    return B \n"
      ],
      "metadata": {
        "id": "vjnGnqwB93a5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "\n",
        "  def __init__(self, sigma):\n",
        "    _ = sigma\n",
        "\n",
        "  def W(self, n_nodes1, n_nodes2):\n",
        "    self.sigma = np.sqrt(2 / n_nodes1)\n",
        "    W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
        "    return W \n",
        "\n",
        "  def B(self, n_nodes2):\n",
        "    B = self.sigma*np.random.randn(1, n_nodes2)\n",
        "    return B "
      ],
      "metadata": {
        "id": "VcurYrE-BFL-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 7 - Optimization Method"
      ],
      "metadata": {
        "id": "YQCIADpzCKH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr \n",
        "\n",
        "  def update(self, layer):\n",
        "    layer.HW += layer.dW * layer.dW\n",
        "    layer.HB += layer.dB * layer.dB\n",
        "    delta = 1e-7\n",
        "    layer.W -=self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
        "    layer.B -=self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
        "    return layer "
      ],
      "metadata": {
        "id": "l5DsMeljCl9w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 8 - Class Completion\n",
        "\n",
        "Let's complete the ScratchDeepNeuralNetrwokClassifier class that can be trained and estimated with any configuration. "
      ],
      "metadata": {
        "id": "5lOJCHQCEjv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "  def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "    self.batch_size = batch_size\n",
        "    np.random.seed(seed)\n",
        "    shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "    self._X = X[shuffle_index]\n",
        "    self._y = y[shuffle_index]\n",
        "    self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._stop\n",
        "\n",
        "  def __getitem__(self, item): \n",
        "    p0 = item*self.batch_size\n",
        "    p1 = item*self.batch_size + self.batch_size\n",
        "    return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "  def __iter__(self): \n",
        "    self._counter = 0\n",
        "    return self \n",
        "\n",
        "  def __next__(self):\n",
        "    if self._counter >= self._stop:\n",
        "      raise StopIteration()\n",
        "    p0 = self._counter*self.batch_size\n",
        "    p1 = self._counter*self.batch_size + self.batch_size \n",
        "    self._counter += 1\n",
        "    return self._X[p0:p1], self._y[p0:p1] \n"
      ],
      "metadata": {
        "id": "tdY6SXGfGc_h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "  def __init__(self, verbose=False, epoch=1, optimizer= SGD, initializer = HeInitializer, activater = ReLU):\n",
        "    self.verbose = verbose\n",
        "    self.batch_size = 20 \n",
        "    self.n_features = 784\n",
        "    self.n_nodes1 = 400\n",
        "    self.n_nodes2 = 400\n",
        "    self.n_output = 10\n",
        "    self.sigma = 0.02\n",
        "    self.lr = 0.5 \n",
        "    self.epoch = epoch\n",
        "    self.optimizer = optimizer\n",
        "    self.initializer = initializer\n",
        "    self.activater = activater\n",
        "\n",
        "  def fit(self, X, y, X_val = None, y_val = None):\n",
        "    self.loss_train = []\n",
        "    self.loss_val = []\n",
        "    optimizer = self.optimizer(self.lr)\n",
        "    self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "    self.activation1 = self.activater()\n",
        "    self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "    self.activation2 = self.activater()\n",
        "    self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "    self.activation3 = softmax()\n",
        "\n",
        "    for i in range(self.epoch):\n",
        "      get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "      for mini_X, mini_y in get_mini_batch:\n",
        "        A1 = self.FC1.forward(mini_X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        # print(Z2.shape)\n",
        "\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        dA3, loss = self.activation3.backward(Z3, mini_y)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC2.backward(dA1)\n",
        "\n",
        "      if self.verbose:\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        self.loss_train.append(self.activation3.backward(Z3, y)[1])\n",
        "\n",
        "        if X_val is not None:\n",
        "          A1 = self.FC1.forward(X_val)\n",
        "          Z1 = self.activation1.forward(A1)\n",
        "          A2 = self.FC2.forward(Z1)\n",
        "          Z2 = self.activation2.forward(A2)\n",
        "          A3 = self.FC3.forward(Z2)\n",
        "          Z3 = self.activation3.forward(A3)\n",
        "          self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
        "\n",
        "  def predict(self, X):\n",
        "    A1 = self.FC1.forward(X)\n",
        "    Z1 = self.activation1.forward(A1)\n",
        "    A2 = self.FC2.forward(Z1)\n",
        "    Z2 = self.activation2.forward(A2)\n",
        "    A3 = self.FC3.forward(Z2)\n",
        "    Z3 = self.activation3.forward(A3)\n",
        "    return np.argmax(Z3, axis=1)\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "axE4PA5nMEVJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 9 - Learning Estimation\n",
        "\n",
        "Let's create several networks with varying numbers of layers and activation functions."
      ],
      "metadata": {
        "id": "IyOGs0EmtFyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "-yiHJsyFumEy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "mlb_VpVKvoq9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis]) "
      ],
      "metadata": {
        "id": "1-9EwM1TwaI1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN = ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) "
      ],
      "metadata": {
        "id": "HMMhZiQaxrpK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = SDNN.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuKNDskEy-Ib",
        "outputId": "75889300-fdd8-495b-b6e8-ddb2f69335b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9565833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN.epoch+1)));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NANLHt_xz2r3",
        "outputId": "42017cae-6b51-43eb-b5b5-603175552a23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the accuracy with other layers, (4 and 6 layers)"
      ],
      "metadata": {
        "id": "-xSu2yiu1Iw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_4():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20 \n",
        "        self.n_features = 784 \n",
        "        self.n_nodes1 = 400 \n",
        "        self.n_nodes2 = 200 \n",
        "        self.n_nodes3 = 150 \n",
        "        self.n_output = 10 \n",
        "        self.sigma = 0.02 \n",
        "        self.lr = 0.5 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = self.activater()\n",
        "        self.FC4 = FC(self.n_nodes3, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation4 = softmax()\n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                self.forward(mini_X)\n",
        "                self.backward(mini_y)\n",
        "            \n",
        "            if self.verbose:\n",
        "                self.forward(X)\n",
        "                self.loss_train.append(self.activation4.backward(self.Z4, y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    self.forward(X_val)\n",
        "                    self.loss_val.append(self.activation4.backward(self.Z4, y_val)[1])\n",
        "    \n",
        "    def forward(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        A4 = self.FC4.forward(Z3)\n",
        "        self.Z4 = self.activation4.forward(A4)\n",
        "        \n",
        "    def backward(self, y):\n",
        "        dA4, self.loss = self.activation4.backward(self.Z4, y) \n",
        "        dZ3 = self.FC4.backward(dA4)\n",
        "        dA3 = self.activation3.backward(dZ3)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC1.backward(dA1) \n",
        "        \n",
        "    def predict(self, X):\n",
        "        self.forward(X)\n",
        "        return np.argmax(self.Z4, axis=1) "
      ],
      "metadata": {
        "id": "4MkjSV7f1k-Y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN4 = ScratchDeepNeuralNetrowkClassifier_4(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN4.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN4.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "qug_HldWKtjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN4.epoch+1)));"
      ],
      "metadata": {
        "id": "TBiPWOOJLdki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_6():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20 \n",
        "        self.n_features = 784 \n",
        "        self.n_nodes1 = 400 \n",
        "        self.n_nodes2 = 200 \n",
        "        self.n_nodes3 = 150 \n",
        "        self.n_nodes4 = 100 \n",
        "        self.n_nodes5 = 50 \n",
        "        self.n_output = 10 \n",
        "        self.sigma = 0.02 \n",
        "        self.lr = 0.5 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = self.activater()\n",
        "        self.FC4 = FC(self.n_nodes3, self.n_nodes4, self.initializer(self.sigma), optimizer)\n",
        "        self.activation4 = self.activater()\n",
        "        self.FC5 = FC(self.n_nodes4, self.n_nodes5, self.initializer(self.sigma), optimizer)\n",
        "        self.activation5 = self.activater()\n",
        "        self.FC6 = FC(self.n_nodes5, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation6 = softmax()\n",
        "        \n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                self.forward(mini_X)\n",
        "                self.backward(mini_y)\n",
        "            \n",
        "            if self.verbose:\n",
        "                self.forward(X)\n",
        "                self.loss_train.append(self.activation6.backward(self.Z6, y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    self.forward(X_val)\n",
        "                    self.loss_val.append(self.activation6.backward(self.Z6, y_val)[1])\n",
        "    \n",
        "    def forward(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        A4 = self.FC4.forward(Z3)\n",
        "        Z4 = self.activation4.forward(A4)\n",
        "        A5 = self.FC5.forward(Z4)\n",
        "        Z5 = self.activation5.forward(A5)\n",
        "        A6 = self.FC6.forward(Z5)\n",
        "        self.Z6 = self.activation6.forward(A6)\n",
        "        \n",
        "    def backward(self, y):\n",
        "        dA6, self.loss = self.activation6.backward(self.Z6, y) \n",
        "        dZ5 = self.FC6.backward(dA6)\n",
        "        dA5 = self.activation5.backward(dZ5)\n",
        "        dZ4 = self.FC5.backward(dA5)\n",
        "        dA4 = self.activation4.backward(dZ4)\n",
        "        dZ3 = self.FC4.backward(dA4)\n",
        "        dA3 = self.activation3.backward(dZ3)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC1.backward(dA1) \n",
        "        \n",
        "    def predict(self, X):\n",
        "        self.forward(X)\n",
        "        return np.argmax(self.Z6, axis=1)  "
      ],
      "metadata": {
        "id": "5jVnvbbsL2li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN6 = ScratchDeepNeuralNetrowkClassifier_6(verbose=True, epoch=10, optimizer= AdaGrad, initializer = HeInitializer, activater = ReLU)\n",
        "\n",
        "SDNN6.fit(X_train, y_train_one_hot, X_val, y_test_one_hot) \n",
        "\n",
        "pred = SDNN6.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "j-2TcxwwTS-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN6.epoch+1)));"
      ],
      "metadata": {
        "id": "DLpO-FRQTr9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, we can say that the accuracy was at its best when we had three layers. \n",
        "\n",
        "Let's finally generalize the ScratchDeepNeuralNetrwokClassifier and make it possible to input layers with the number of nodes. "
      ],
      "metadata": {
        "id": "zhdNIJaxUGKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class General_ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU, n_nodes=None):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20 \n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "        self.n_nodes = n_nodes \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = [] \n",
        "        optimizer = self.optimizer(self.lr)\n",
        "        self.fcs = [] \n",
        "        self.act = [] \n",
        "        \n",
        "        for i in range(len(self.n_nodes)-2):\n",
        "            self.fcs.append(FC(self.n_nodes[i], self.n_nodes[i+1], self.initializer(self.sigma), optimizer))\n",
        "            self.act.append(self.activater())\n",
        "        self.fcs.append(FC(self.n_nodes[i+1], self.n_nodes[-1], self.initializer(self.sigma), optimizer))\n",
        "        self.act.append(softmax())\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                A = []\n",
        "                Z = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                    if i == 0:\n",
        "                        A.append(f.forward(mini_X))\n",
        "                        Z.append(a.forward(A[i]))\n",
        "                    else:\n",
        "                        A.append(f.forward(Z[i-1]))\n",
        "                        Z.append(a.forward(A[i]))     \n",
        "                dA = []\n",
        "                dZ = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs[::-1], self.act[::-1])):\n",
        "                    if i == 0:\n",
        "                        dA.append(a.backward(Z[-(i+1)], mini_y)[0])\n",
        "                        dZ.append(f.backward(dA[i]))\n",
        "                    else:\n",
        "                        dA.append(a.backward(dZ[i-1]))\n",
        "                        dZ.append(f.backward(dA[i]))\n",
        "\n",
        "            if self.verbose:\n",
        "                A = []\n",
        "                Z = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                    if i == 0:\n",
        "                        A.append(f.forward(X))\n",
        "                        Z.append(a.forward(A[i]))\n",
        "                    else:\n",
        "                        A.append(f.forward(Z[i-1]))\n",
        "                        Z.append(a.forward(A[i]))           \n",
        "                self.loss_train.append(self.act[-1].backward(Z[-1], y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    A = []\n",
        "                    Z = []\n",
        "                    for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                        if i == 0:\n",
        "                            A.append(f.forward(X_val))\n",
        "                            Z.append(a.forward(A[i]))\n",
        "                        else:\n",
        "                            A.append(f.forward(Z[i-1]))\n",
        "                            Z.append(a.forward(A[i]))           \n",
        "                    self.loss_val.append(self.act[-1].backward(Z[-1], y_val)[1])\n",
        "    \n",
        "    def predict(self, X):\n",
        "        A = []\n",
        "        Z = []\n",
        "        for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "            if i == 0:\n",
        "                A.append(f.forward(X))\n",
        "                Z.append(a.forward(A[i]))\n",
        "            else:\n",
        "                A.append(f.forward(Z[i-1]))\n",
        "                Z.append(a.forward(A[i]))\n",
        "        return np.argmax(Z[-1], axis=1)"
      ],
      "metadata": {
        "id": "QOXKxpH2VUcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it with five layers"
      ],
      "metadata": {
        "id": "et0z6NVGgrd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_list = [784, 400, 200, 150, 100, 10]\n",
        "SDNN5 = General_ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU, n_nodes=node_list)\n",
        "SDNN5.fit(X_train, y_train_one_hot, X_val, y_test_one_hot)\n",
        "pred = SDNN5.predict(X_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "YegKsBGLgxN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN5.epoch+1)), SDNN5.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN5.epoch+1)), SDNN5.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN5.epoch+1)));"
      ],
      "metadata": {
        "id": "otTDcKhDh8-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}